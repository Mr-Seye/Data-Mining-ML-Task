{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eabd0316-5ef6-41d3-a818-084153050c08",
   "metadata": {},
   "source": [
    "#Data Minining and Machine Learning\n",
    "##  Task 4 - Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd9fd435-e51a-448e-a28f-11fcdce37dc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyper-parameters\n",
    "# User can change the number of components for PCA\n",
    "# to 2 or 3\n",
    "dims = 3\n",
    "\n",
    "# User can change number of desired clusters for\n",
    "# application of KMeans clustering and plotting\n",
    "clusters = 8\n",
    "\n",
    "# Max iterations for KMeans clustering and random \n",
    "# seed for weights\n",
    "k_iter = 300\n",
    "k_rand_state = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df6c0cce-dfa1-4fbc-bbf4-0a6cf70e815f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This block takes the pre-processing block from task 1 (as asked) to use\n",
    "# for this task.\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "train_data = np.load('x_train.npy')\n",
    "train_labels = np.load('y_train.npy')\n",
    "test_data = np.load('x_test.npy')\n",
    "test_labels = np.load('y_test.npy')\n",
    "\n",
    "scaler = StandardScaler()\n",
    "train_data_scaled = scaler.fit_transform(train_data)\n",
    "test_data_scaled = scaler.transform(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43d1bd85-5b2e-4aaf-aa37-92639c7706df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This block initialises the PCA function and a component parameter\n",
    "# it then performs a reduction on the dataset.\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components = dims)\n",
    "train_data_pca = pca.fit_transform(train_data_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52dc1be0-35e1-4221-b28e-3b7a72ea623b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This block uses an if statement to produce either a 3D or 2D\n",
    "# plot depending on the number of components specified\n",
    "# (should be 2 or 3).\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "if dims >= 3:\n",
    "    fig = plt.figure(figsize=(10, 8))\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "    scatter = ax.scatter(train_data_pca[:, 0], train_data_pca[:, 1], train_data_pca[:, 2], c=train_labels, cmap='viridis', edgecolor='k', s=50)\n",
    "    ax.set_title('PCA-reduced Data (3D)')\n",
    "    ax.set_xlabel('Principal Component 1')\n",
    "    ax.set_ylabel('Principal Component 2')\n",
    "    ax.set_zlabel('Principal Component 3')\n",
    "    plt.colorbar(scatter, ax=ax, label='Class')\n",
    "    plt.show()\n",
    "elif dims == 2:\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.scatter(train_data_pca[:, 0], train_data_pca[:, 1], c=train_labels, cmap='viridis', edgecolor='k', s=50)\n",
    "    plt.title('PCA-reduced Data')\n",
    "    plt.xlabel('Principal Component 1')\n",
    "    plt.ylabel('Principal Component 2')\n",
    "    plt.colorbar(label='Class')\n",
    "    plt.show()\n",
    "elif dims == 1:\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.scatter(train_data_pca[:, 0], np.zeros_like(train_data_pca[:, 0]), c=train_labels, cmap='viridis', edgecolor='k', s=50)\n",
    "    plt.title('PCA-reduced Data')\n",
    "    plt.xlabel('Principal Component 1')\n",
    "    plt.ylabel('Class')\n",
    "    plt.colorbar(label='Class')\n",
    "    plt.show()\n",
    "else:\n",
    "    print('Dimensionality is invalid.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "901f2b38-0e47-477f-918e-9509473ee3f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This block implements the KMeans clustering\n",
    "# algorithm on the reduced data.\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# Clustering on PCA-reduced data with\n",
    "# random state seed of 42\n",
    "# Number of clusters can be specified, for\n",
    "# this dataset, not specifying a cluster number\n",
    "# KMeans defaults to 8 clusters.\n",
    "kmeans = KMeans(n_init='auto', n_clusters=clusters ,max_iter=k_iter, random_state=k_rand_state)\n",
    "kmeans.fit(train_data_pca)\n",
    "cluster_labels = kmeans.predict(train_data_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13e7a7bd-c602-4b9d-aaad-774de0f08fd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Like the other plot block, this block uses an \n",
    "# if statement to produce either a 3D or 2D\n",
    "# plot depending on the number of components specified\n",
    "# (should be 2 or 3).\n",
    "\n",
    "if dims >= 3:\n",
    "    fig = plt.figure(figsize=(10, 8))\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "    ax.scatter(train_data_pca[:, 0], train_data_pca[:, 1], train_data_pca[:, 2], c=cluster_labels, cmap='viridis', edgecolor='k', s=50)\n",
    "    ax.set_title('Clustering on PCA-reduced Data (3D)')\n",
    "    ax.set_xlabel('Principal Component 1')\n",
    "    ax.set_ylabel('Principal Component 2')\n",
    "    ax.set_zlabel('Principal Component 3')\n",
    "    plt.show()\n",
    "elif dims == 2:\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.scatter(train_data_pca[:, 0], train_data_pca[:, 1], c=cluster_labels, cmap='viridis', edgecolor='k', s=50)\n",
    "    plt.title('Clustering on PCA-reduced Data')\n",
    "    plt.xlabel('Principal Component 1')\n",
    "    plt.ylabel('Principal Component 2')\n",
    "    plt.colorbar(label='Cluster')\n",
    "    plt.show()\n",
    "elif dims == 1:\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.scatter(train_data_pca[:, 0], np.zeros_like(train_data_pca[:, 0]), c=cluster_labels, cmap='viridis', edgecolor='k', s=50)\n",
    "    plt.title('Clustering on PCA-reduced Data')\n",
    "    plt.xlabel('Principal Component 1')\n",
    "    plt.ylabel('Cluster')\n",
    "    plt.colorbar(label='Cluster')\n",
    "    plt.show()\n",
    "else:\n",
    "    print('Dimensionality is invalid.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3666362-5e67-4386-84ef-aa22e0168695",
   "metadata": {},
   "source": [
    "# Markdown Question\n",
    "\n",
    "How do you think the visualisation will change if you used 3 PCA components?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4338da61-9414-4193-a105-3615a89cf7d0",
   "metadata": {},
   "source": [
    "#### Answer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3892659-fad2-47be-8769-f7c3972479f1",
   "metadata": {},
   "source": [
    "Using 3 PCA components instead of 2 introduces a third dimension to the reduced data and will change the visualization in the following ways:\n",
    "\n",
    "Given that we now have a new dimension the visualisation will now have to be in a 3-dimensional space in order to properly display the clustering instead of a 2-dimensional space. This would introduce a third principle component.\n",
    "\n",
    "The visualisation may remain similar if viewed from a 'similar' plane but the introduction of an additional dimension allows for the relationship between each individual point and cluster's relationship with the new component.\n",
    "\n",
    "Additionally, using 3 PCA components may provide a richer representation of the data, allowing for a more detailed exploration of its structure and relationships."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
