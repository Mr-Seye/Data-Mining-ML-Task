{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e76f6c9a-0a36-44d8-9666-ce22c9820487",
   "metadata": {},
   "source": [
    "#Data Minining and Machine Learning\n",
    "##  Task 3 - Hypothesis Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3616febb-8ec5-45cc-9867-df68ecb59cd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyper-parameters\n",
    "\n",
    "# Specified range for feature selection\n",
    "feat_range = (10, 15)\n",
    "\n",
    "# SVC kernel type and max number of iteration\n",
    "# -1 is no limit (default)\n",
    "svm_kern = 'linear'\n",
    "svm_iter = -1\n",
    "\n",
    "# Number of units and layers in MLP hidden\n",
    "# layers (100,) is 1 layer of 100 units\n",
    "# Max number of iterations, seed for random weighting of\n",
    "# units and the learn rate.\n",
    "mlp_layer_sizes = (100,)\n",
    "mlp_iter = 500\n",
    "mlp_rand_state = 42\n",
    "mlp_learn_rate = 0.001\n",
    "\n",
    "# Number of cross validation folds\n",
    "n_cross_val = 10\n",
    "\n",
    "# Significance value for hypothesis testing\n",
    "alpha = 0.05\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5225930e-cc76-44ac-913f-1fc57d60ce42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This block takes the preprocessing block from task 1 (as asked) \n",
    "# to use for this task\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "train_data = np.load('x_train.npy')\n",
    "train_labels = np.load('y_train.npy')\n",
    "test_data = np.load('x_test.npy')\n",
    "test_labels = np.load('y_test.npy')\n",
    "\n",
    "scaler = MinMaxScaler(feature_range=feat_range)\n",
    "train_data_scaled = scaler.fit_transform(train_data)\n",
    "test_data_scaled = scaler.transform(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33f6983b-6caf-40a9-bd30-dbd545dc59e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This block initialises an SVC with a linear kernel, trains it and makes\n",
    "# predictions on the test set.\n",
    "# It also stores precision, recall and area under curve scores for later \n",
    "# evaluation.\n",
    "# Lastly, a Precision-Recall Curve for all 10 classification is plotted.\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import precision_recall_curve, auc\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "svm_classifier = SVC(kernel=svm_kern, max_iter=svm_iter)\n",
    "svm_classifier.fit(train_data_scaled, train_labels)\n",
    "svm_predictions = svm_classifier.decision_function(test_data_scaled)\n",
    "\n",
    "precision = dict()\n",
    "recall = dict()\n",
    "auc_score = dict()\n",
    "for i in range(len(svm_classifier.classes_)):\n",
    "    precision[i], recall[i], _ = precision_recall_curve(test_labels == i, svm_predictions[:, i])\n",
    "    auc_score[i] = auc(recall[i], precision[i])\n",
    "\n",
    "plt.figure()\n",
    "for i in range(len(svm_classifier.classes_)):\n",
    "    plt.plot(recall[i], precision[i], label=f'Class {i} (AUC = {auc_score[i]:0.2f})')\n",
    "\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.title('SVM Precision-Recall Curve (Per Class)')\n",
    "plt.legend(loc='lower left')\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70c55da7-4fc1-4d8e-a089-db40fbaac6af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This block initialises an MLP, trains it and makes predictions on the test set.\n",
    "# Like the SVC block it also stores precision, recall and area under curve scores \n",
    "# for later evaluation\n",
    "# It also plots a Precision-Recall Curve for all 10 classifications.\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import precision_recall_curve, auc\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "mlp_classifier = MLPClassifier(hidden_layer_sizes=mlp_layer_sizes, learning_rate_init=mlp_learn_rate, max_iter=mlp_iter, random_state=mlp_rand_state)\n",
    "mlp_classifier.fit(train_data_scaled, train_labels)\n",
    "mlp_predictions = mlp_classifier.predict_proba(test_data_scaled)\n",
    "\n",
    "precision = dict()\n",
    "recall = dict()\n",
    "auc_score = dict()\n",
    "for i in range(len(mlp_classifier.classes_)):\n",
    "    precision[i], recall[i], _ = precision_recall_curve(test_labels == i, mlp_predictions[:, i])\n",
    "    auc_score[i] = auc(recall[i], precision[i])\n",
    "\n",
    "plt.figure()\n",
    "for i in range(len(mlp_classifier.classes_)):\n",
    "    plt.plot(recall[i], precision[i], label=f'Class {i} (AUC = {auc_score[i]:0.2f})')\n",
    "\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.title('MLP Precision-Recall Curve (Per Class)')\n",
    "plt.legend(loc='lower left')\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "501f50ec-6cc4-4361-a22b-6d81bd84be7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This block performs Cross-Validation (CV) on both classifiers.\n",
    "# This is to collect scores to perform an independent T-Test to obtain a ρ-value\n",
    "# for our hypothesis test.\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from scipy import stats\n",
    "from scipy.stats import ttest_ind\n",
    "\n",
    "svm_classifier = SVC(kernel=svm_kern, max_iter=svm_iter)\n",
    "svm_classifier.fit(train_data_scaled, train_labels)\n",
    "svm_scores = cross_val_score(svm_classifier, train_data_scaled, train_labels, cv=n_cross_val)\n",
    "\n",
    "# MLP Classifier\n",
    "mlp_classifier = MLPClassifier(hidden_layer_sizes=mlp_layer_sizes, learning_rate_init=mlp_learn_rate, max_iter=mlp_iter, random_state=mlp_rand_state)\n",
    "mlp_classifier.fit(train_data_scaled, train_labels)\n",
    "mlp_scores = cross_val_score(mlp_classifier, train_data_scaled, train_labels, cv=n_cross_val)\n",
    "\n",
    "\n",
    "#ttest_ind(svm_scores, mlp_scores)\n",
    "\n",
    "t_statistic, p_value = stats.ttest_ind(svm_scores, mlp_scores)\n",
    "\n",
    "print(\"SVM Scores:\", svm_scores)\n",
    "print(\"Mean SVM Score:\", np.mean(svm_scores))\n",
    "print(\"MLP Scores:\", mlp_scores)\n",
    "print(\"Mean MLP Score:\", np.mean(mlp_scores))\n",
    "\n",
    "print(\"\\nT-test Results:\")\n",
    "print(\"T-statistic:\", t_statistic)\n",
    "print(\"ρ-value:\", p_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "321654d2-c4dc-4538-8212-cd6ac5db54c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This block simply compares a chosen α to compare the obtained ρ-value from the\n",
    "# previous block to make our conclusion on our hypothesis test.\n",
    "\n",
    "if p_value < alpha:\n",
    "    if np.mean(svm_scores) > np.mean(mlp_scores):\n",
    "        print(\"Reject null hypothesis: SVM performs significantly better than MLP.\")\n",
    "    else:\n",
    "        print(\"Reject null hypothesis: MLP performs significantly better than SVM.\")\n",
    "    \n",
    "else:\n",
    "    print(\"Fail to reject null hypothesis: No significant difference between SVM and MLP.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64e072b0-037e-4bc7-a877-2516cc5af85c",
   "metadata": {},
   "source": [
    "# Markdown Question\n",
    "\n",
    "What was the hypothesis you rejected in this task?\n",
    "How does p-value affect your decision?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d58c1824-5a9a-45d7-969f-a29606ad2d93",
   "metadata": {},
   "source": [
    "#### Answer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e70f9ed6-4b1f-4ee7-b866-5a9b20788b71",
   "metadata": {},
   "source": [
    "Say there exists two hypotheses, a null hypothesis (H0) and an alternative hypothesis (H1) where,\n",
    "\n",
    "* Null Hypothesis (H0): states that there is no significant difference in performance between the SVM and MLP classifiers.\n",
    "\n",
    "* Alternative Hypothesis (H1): states that there is significant difference in performance between the SVM and MLP classifiers across all performance metrics.\n",
    "\n",
    "* and an arbitrary α = 0.05 (significance value of 0.05).\n",
    "\n",
    "Given α = 0.05 or 5 × 10-2 and\n",
    "\n",
    "ρ = 3.0388433316268643 × 10-6\n",
    "\n",
    "A run of this program gave a ρ-value 3.0388433316268643 × 10-6 < 5x10-2 which means the null hypothesis is rejected and the alternative hypothesis which is that there is a significant performance difference is accepted. Based on the accuracy values the SVM is 'significantly' better at classifying the elements of the dataset correctly."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
